
# Recursos para el Aprendizaje y Desarrollo en Machine Learning

Este repositorio re√∫ne conceptos, pr√°cticas y ejemplos de c√≥digo para entender y aplicar t√©cnicas de Machine Learning en diversos contextos acad√©micos y de investigaci√≥n. Est√° dise√±ado para profesores, investigadores y estudiantes que desean profundizar en los principios y herramientas fundamentales que impulsan el campo de Machine Learning, desde algoritmos b√°sicos hasta modelos avanzados de aprendizaje profundo.

---

## **Visualizaci√≥n de una Red Neuronal en Entrenamiento**

![Red Neuronal en Entrenamiento](https://github.com/sgevatschnaider/machine-learning/blob/904ce259b00f331c9d0d550d0870ff4771e73033/recursos/red%20neuronal.gif)

La animaci√≥n anterior muestra una red neuronal artificial entren√°ndose en tiempo real. Las capas densas (fully connected) reciben y propagan se√±ales a trav√©s de sus nodos, y los pesos se ajustan continuamente durante el proceso de retropropagaci√≥n. A la derecha se observan m√©tricas clave del entrenamiento, incluyendo la precisi√≥n (`accuracy`), la funci√≥n de p√©rdida (`loss`) y el n√∫mero de √©pocas (`epochs`) ya completadas. Esta representaci√≥n visual es ideal para comprender intuitivamente el aprendizaje profundo y c√≥mo evolucionan los modelos a lo largo del tiempo.

---
## **Contenido**
1. [Fundamentos de Machine Learning](#1-fundamentos-de-machine-learning)
2. [Modelos Cl√°sicos de Machine Learning](#2-modelos-cl√°sicos-de-machine-learning)
3. [Redes Neuronales y Aprendizaje Profundo](#3-redes-neuronales-y-aprendizaje-profundo)
4. [Aprendizaje por Refuerzo (Reinforcement Learning)](#4-aprendizaje-por-refuerzo-reinforcement-learning)
5. [Procesamiento de Lenguaje Natural (NLP)](#5-procesamiento-de-lenguaje-natural-nlp)
6. [Visualizaci√≥n y An√°lisis de Datos](#6-visualizaci√≥n-y-an√°lisis-de-datos)
7. [Ejemplos y Casos de Estudio](#7-ejemplos-y-casos-de-estudio)

---

## **1. Fundamentos de Machine Learning**
Conceptos b√°sicos y fundamentos necesarios para comenzar en Machine Learning.

- **Tipos de Aprendizaje**: Introducci√≥n a los tipos de aprendizaje supervisado, no supervisado, semi-supervisado y por refuerzo.
- **Procesamiento de Datos**: T√©cnicas para limpieza y preparaci√≥n de datos, incluyendo manejo de datos faltantes, normalizaci√≥n y transformaci√≥n de datos.
- **Evaluaci√≥n de Modelos**: M√©tricas de evaluaci√≥n para clasificaciones, regresiones y clustering (precisi√≥n, recall, F1-score, MSE, etc.).

---

## **2. Modelos Cl√°sicos de Machine Learning**
Implementaci√≥n de algoritmos tradicionales de Machine Learning y sus aplicaciones.

- **Regresi√≥n Lineal y Log√≠stica**: Modelos b√°sicos para tareas de predicci√≥n y clasificaci√≥n.
- **√Årboles de Decisi√≥n y Bosques Aleatorios**: Algoritmos de √°rbol para clasificaci√≥n y regresi√≥n.
- **M√°quinas de Soporte Vectorial (SVM)**: Modelos para clasificaci√≥n con m√°rgenes √≥ptimos.
- **K-Means y Clustering**: T√©cnicas de agrupamiento para an√°lisis no supervisado.

---

## **3. Redes Neuronales y Aprendizaje Profundo**
Introducci√≥n y pr√°ctica con redes neuronales y modelos avanzados de deep learning.

- **Redes Neuronales Artificiales (ANNs)**: Conceptos b√°sicos y ejemplos de redes de perceptrones multicapa.
- **Redes Convolucionales (CNNs)**: Aplicaciones en visi√≥n por computadora.
- **Redes Recurrentes (RNNs)**: Modelos para secuencias de datos, como series temporales y procesamiento de texto.
- **Transfer Learning**: C√≥mo aprovechar modelos preentrenados para mejorar la eficiencia y precisi√≥n.

---

## **4. Aprendizaje por Refuerzo (Reinforcement Learning)**
Exploraci√≥n de algoritmos y conceptos fundamentales del aprendizaje por refuerzo.

- **Fundamentos del Aprendizaje por Refuerzo**: Introducci√≥n a conceptos clave como agentes, estados, acciones, recompensas y entorno.
- **M√©todos de Control Basados en Pol√≠ticas**: Estrategias como SARSA y Q-learning.
- **Aprendizaje Profundo en RL**: Implementaciones avanzadas como Deep Q-Networks (DQN) y Aprendizaje A3C.
- **Casos de Uso**: Aplicaciones en videojuegos, rob√≥tica y optimizaci√≥n de procesos.

---

## **5. Procesamiento de Lenguaje Natural (NLP)**
T√©cnicas y modelos para trabajar con datos textuales.

- **Representaci√≥n de Textos**: M√©todos como Bag of Words, TF-IDF y embeddings (Word2Vec, GloVe).
- **Modelos de NLP**: Implementaci√≥n de algoritmos de clasificaci√≥n de texto, an√°lisis de sentimiento y generaci√≥n de texto.
- **Transformers y BERT**: Introducci√≥n a los modelos avanzados de NLP, incluyendo ejemplos con BERT y GPT.

---

## **6. Visualizaci√≥n y An√°lisis de Datos**
Herramientas y t√©cnicas para explorar y visualizar datos.

- **Visualizaci√≥n de Datos**: Gr√°ficas y diagramas para el an√°lisis de datos, utilizando librer√≠as como Matplotlib y Seaborn.
- **An√°lisis Exploratorio de Datos (EDA)**: T√©cnicas para entender la distribuci√≥n y patrones de los datos antes de aplicar modelos.

---

## **7. Ejemplos y Casos de Estudio**
Aplicaciones pr√°cticas de Machine Learning en diferentes √°reas.

- **Predicci√≥n de Precios**: Aplicaci√≥n de modelos de regresi√≥n para la predicci√≥n de precios de bienes.
- **Clasificaci√≥n de Im√°genes**: Uso de CNNs para clasificar im√°genes en diferentes categor√≠as.
- **An√°lisis de Sentimientos en Redes Sociales**: Clasificaci√≥n de texto para identificar sentimientos en comentarios de redes sociales.

---

## **Estructura del Repositorio**
```plaintext
machine-learning-research/
‚îú‚îÄ‚îÄ data/                  # Datos de entrada (datasets para entrenar modelos)
‚îú‚îÄ‚îÄ notebooks/             # Notebooks de Jupyter para experimentos y demostraciones
‚îÇ   ‚îú‚îÄ‚îÄ es/                # Notebooks en espa√±ol
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Estad√≠stica_Paradigma_EDA_y_p.ipynb
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Aprendizaje_por_Refuerzo_en_Lenguaje_Natural_(NLRL).ipynb
‚îÇ   ‚îú‚îÄ‚îÄ en/                # Notebooks en ingl√©s
‚îÇ       ‚îú‚îÄ‚îÄ Statistics_EDA.ipynb
‚îÇ       ‚îú‚îÄ‚îÄ Natural_Language_Reinforcement_Learning_(NLRL).ipynb
‚îú‚îÄ‚îÄ scripts/               # Scripts de Python para procesamiento y entrenamiento
‚îú‚îÄ‚îÄ models/                # Modelos entrenados para pruebas y evaluaciones
‚îú‚îÄ‚îÄ results/               # Resultados, gr√°ficas y visualizaciones
‚îú‚îÄ‚îÄ references/            # Art√≠culos, papers y material de referencia
‚îî‚îÄ‚îÄ README.md              # Documentaci√≥n del repositorio
```

---
## Fundamentos de Inteligencia Artificial y Machine Learning

Esta secci√≥n contiene notebooks te√≥ricos y conceptuales que establecen las bases para entender el campo de la IA, sus subcategor√≠as y los diferentes enfoques de aprendizaje.

| üìÑ Recurso | üì• Acceso |
| :--- | :--- |
| **Introducci√≥n a la IA y Machine Learning** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Este notebook es una gu√≠a introductoria y puramente conceptual que desglosa y clarifica los t√©rminos fundamentales del mundo de la Inteligencia Artificial. Es el punto de partida ideal para cualquiera que desee entender el "qu√©" y el "porqu√©" antes de sumergirse en el "c√≥mo".<br><br><h4>Jerarqu√≠a de Conceptos</h4><p>Explica la relaci√≥n entre los campos principales, a menudo representados como c√≠rculos conc√©ntricos:</p><ul><li><strong>Inteligencia Artificial (IA):</strong> El campo m√°s amplio, enfocado en crear m√°quinas que puedan simular la inteligencia humana (razonar, aprender, resolver problemas).</li><li><strong>Machine Learning (ML):</strong> Un subconjunto de la IA que se centra en algoritmos que permiten a las m√°quinas aprender de los datos para identificar patrones y tomar decisiones sin ser programadas expl√≠citamente para cada tarea.</li><li><strong>Deep Learning (DL):</strong> Un subconjunto del ML que utiliza redes neuronales artificiales con m√∫ltiples capas ("profundas") para resolver problemas complejos, especialmente en √°reas como el reconocimiento de im√°genes y el procesamiento del lenguaje natural.</li></ul><h4>Tipos de Aprendizaje Autom√°tico (Machine Learning)</h4><p>El notebook detalla los tres paradigmas principales del ML:</p><ol><li><strong>Aprendizaje Supervisado:</strong> Entrenar un modelo con datos "etiquetados" (donde ya conocemos la respuesta correcta). Se divide en:<ul><li><strong>Regresi√≥n:</strong> Predecir un valor num√©rico continuo (ej: el precio de una casa).</li><li><strong>Clasificaci√≥n:</strong> Predecir una categor√≠a o clase (ej: si un correo es spam o no).</li></ul></li><li><strong>Aprendizaje No Supervisado:</strong> Entrenar un modelo con datos "no etiquetados" para que encuentre patrones o estructuras ocultas por s√≠ mismo. Incluye:<ul><li><strong>Clustering:</strong> Agrupar datos similares (ej: segmentaci√≥n de clientes).</li></ul></li><li><strong>Aprendizaje por Refuerzo:</strong> Un "agente" aprende a tomar decisiones interactuando con un entorno. Recibe "recompensas" o "castigos" por sus acciones, con el objetivo de maximizar la recompensa total. Es la base de muchos sistemas de juegos (AlphaGo) y rob√≥tica.</li></ol></p></details> | [![Ver en GitHub](https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/machine-learning/blob/1c135db89f4acc380588fb81996dd7320f766a56/notebooks/Machine_Learning_Inteligencia_artificial.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sgevatschnaider/machine-learning/blob/main/notebooks/Machine_Learning_Inteligencia_artificial.ipynb) |




##  Aprendizaje Autom√°tico (Machine Learning)

| üìÑ Recurso | üì• Acceso |
| :--- | :--- |
| **Introducci√≥n al Machine Learning** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Este notebook proporciona una introducci√≥n conceptual al campo del Machine Learning. Define qu√© es, explora sus aplicaciones pr√°cticas y distingue entre los principales tipos de aprendizaje (supervisado, no supervisado y por refuerzo). Adem√°s, introduce la terminolog√≠a fundamental como modelos, caracter√≠sticas (features) y etiquetas (labels), sentando las bases te√≥ricas para el estudio de algoritmos m√°s complejos.</p></details> | <a href="https://github.com/sgevatschnaider/machine-learning/blob/1e243455df8027e527fc903191626af477132439/notebooks/es/Machine_Learning_Introducci%C3%B3n_a_la_materia_.ipynb" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github" alt="Ver en GitHub"></a> <a href="https://colab.research.google.com/github/sgevatschnaider/machine-learning/blob/main/notebooks/es/Machine_Learning_Introducci%C3%B3n_a_la_materia_.ipynb" target="_blank" rel="noopener noreferrer"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a> |

##  Probabilidad y Estad√≠stica

| üìÑ Recurso | üì• Acceso |
| :--- | :--- |
| **Notebook: Fundamentos de Probabilidad y Estad√≠stica** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Un notebook esencial que cubre los pilares de la probabilidad y la estad√≠stica, conceptos indispensables para el Machine Learning. Explora temas como estad√≠stica descriptiva (media, varianza), distribuciones de probabilidad y teoremas clave. Este material es crucial para entender c√≥mo se analizan los datos, se eval√∫an los modelos y se cuantifica la incertidumbre en las predicciones.</p></details> | <a href="https://github.com/sgevatschnaider/machine-learning/blob/a4f6115bbf6382254703d03864ca163415f9edc2/notebooks/es/Probabilidad_y_estadistica_.ipynb" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github" alt="Ver en GitHub"></a> <a href="https://colab.research.google.com/github/sgevatschnaider/machine-learning/blob/main/notebooks/es/Probabilidad_y_estadistica_.ipynb" target="_blank" rel="noopener noreferrer"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a> |


---

| üìÑ Recurso | Enlaces |
|---|---|
| **Probabilidad, Estad√≠stica y Funciones Hash** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Notebook que repasa nociones clave de probabilidad y estad√≠stica y las conecta con el comportamiento de las funciones hash: uniformidad, colisiones, integridad de datos y aplicaciones en seguridad. Incluye ejemplos en Python.</p></details> | [![Ver en GitHub](https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/machine-learning/blob/9f86d0721e8cd2810e9e8b579f00722460ae4c7f/notebooks/es/Probabilidad_%2C_estad%C3%ADstica__Funciones_hash.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sgevatschnaider/machine-learning/blob/9f86d0721e8cd2810e9e8b579f00722460ae4c7f/notebooks/es/Probabilidad_%2C_estad%C3%ADstica__Funciones_hash.ipynb) |
| **Entrop√≠a (Informaci√≥n e Incertidumbre)** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Recurso sobre entrop√≠a como medida de incertidumbre/informaci√≥n en distribuciones de probabilidad. Discute intuiciones, ejemplos num√©ricos y usos en machine learning, compresi√≥n y teor√≠a de la informaci√≥n.</p></details> | [![Abrir P√°gina Interactiva](https://img.shields.io/badge/Abrir%20P√°gina-Interactiva-brightgreen?style=for-the-badge&logo=html5)](https://sgevatschnaider.github.io/machine-learning/recursos/entropia.html) |

| üìÑ Recurso | Enlaces |
|---|---|
| **Problema de Fermi y la Sabidur√≠a de Masas** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Este notebook explora el cl√°sico "Problema de Fermi" y el concepto de sabidur√≠a de masas, mostrando c√≥mo las estimaciones colectivas pueden acercarse sorprendentemente a la realidad. Incluye teor√≠a, ejemplos y aplicaciones en inteligencia colectiva y an√°lisis de datos.</p></details> | [![Ver en GitHub](https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/IA-Teoria-Practica/blob/1d71e15637c6a3f2fa32698ab8bb420e5135ad3f/notebooks/Problema_de_Fermi_y_la_Sabidur%C3%ADa_de_masas.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sgevatschnaider/IA-Teoria-Practica/blob/1d71e15637c6a3f2fa32698ab8bb420e5135ad3f/notebooks/Problema_de_Fermi_y_la_Sabidur%C3%ADa_de_masas.ipynb) |


### Distribuciones Discretas y Continuas

| üìÑ Recurso | üì• Acceso |
| :--- | :--- |
| **Distribuciones Discretas y Continuas** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Notebook dedicado al estudio de las distribuciones de probabilidad discretas y continuas, esenciales en estad√≠stica y machine learning. Incluye explicaciones te√≥ricas, ejemplos pr√°cticos, visualizaciones y casos de uso en la modelizaci√≥n y el an√°lisis de datos.</p></details> | [![Ver Notebook](https://img.shields.io/badge/Ver%20Notebook-en%20GitHub-orange?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/machine-learning/blob/a33017fcb85f0a2f4656518ce0db8eab7d072890/notebooks/es/Distribuciones_discretas_y_continuas.ipynb) |

### Regresi√≥n Lineal, Outliers y Random Forest e Hiperpar√°metros 

| üìÑ Notebook | üì• Acceso |
| :--- | :--- |
| **Regresi√≥n Lineal** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Notebook enfocado en la regresi√≥n lineal, uno de los modelos fundamentales en estad√≠stica y machine learning. Incluye fundamentos te√≥ricos, ejemplos pr√°cticos, an√°lisis de resultados y visualizaciones para comprender la relaci√≥n entre variables.</p></details> | [![Ver Notebook](https://img.shields.io/badge/Ver%20Notebook-en%20GitHub-orange?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/machine-learning/blob/8d5368e5d9e37830efe7641fc6642d5c9622b6b3/notebooks/es/Regresion_Lineal.ipynb) |
| **Outliers** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Notebook dedicado a la detecci√≥n y an√°lisis de outliers (valores at√≠picos) en conjuntos de datos. Presenta m√©todos estad√≠sticos, ejemplos pr√°cticos y visualizaciones para identificar, tratar e interpretar outliers en an√°lisis de datos y modelos predictivos.</p></details> | [![Ver Notebook](https://img.shields.io/badge/Ver%20Notebook-en%20GitHub-orange?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/machine-learning/blob/76504b3ca948a777ef8bb2eb77115a33add738b7/notebooks/es/Outliers.ipynb) |
| **Random Forest e Hiperpar√°metros** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Notebook dedicado a la t√©cnica de Random Forest, un modelo de ensamble ampliamente utilizado en machine learning. Incluye teor√≠a, ejemplos pr√°cticos y estrategias para la selecci√≥n de hiperpar√°metros.</p></details> | [![Ver Notebook](https://img.shields.io/badge/Ver%20Notebook-en%20GitHub-orange?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/machine-learning/blob/64d5d3e366332b38952f444d5666c07d725302c5/notebooks/es/Random_forest_e_hiperpar%C3%A1metros_.ipynb) |

| üìÑ Recurso | Enlaces |
|---|---|
| **Sesgo, Varianza y Entrop√≠a** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Notebook que explica los conceptos fundamentales de sesgo, varianza y entrop√≠a en el contexto de modelos de machine learning. Incluye ejemplos, visualizaciones y aplicaciones pr√°cticas para comprender el equilibrio entre estos conceptos en la construcci√≥n de modelos predictivos.</p></details> | [![Ver en GitHub](https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/machine-learning/blob/0d8037f01f56a159a530ab1e8c255d5433b2ee23/notebooks/es/Sesgo%2C_Varianza_y_entropia.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sgevatschnaider/machine-learning/blob/0d8037f01f56a159a530ab1e8c255d5433b2ee23/notebooks/es/Sesgo%2C_Varianza_y_entropia.ipynb) |


## **Instalaci√≥n y Configuraci√≥n**
Para ejecutar los ejemplos de este repositorio, aseg√∫rate de tener instalado Python (3.7 o superior) y los paquetes necesarios listados en `requirements.txt`.

### Clona el repositorio:
```bash
git clone https://github.com/tu-usuario/machine-learning-research.git
cd machine-learning-research
```

### Instala las dependencias necesarias:
```bash
pip install -r requirements.txt
```

---

## **Ejecuci√≥n de Ejemplos**
Cada carpeta incluye instrucciones espec√≠ficas para ejecutar los ejemplos. Puedes ejecutar los notebooks de Jupyter directamente para seguir los pasos de cada proyecto o utilizar los scripts para realizar pruebas y evaluaciones autom√°ticas.

---

## **Contribuciones**
Las contribuciones son bienvenidas. Si deseas agregar nuevos ejemplos o mejorar los existentes, sigue estos pasos:

1. Haz un fork del repositorio.
2. Crea una nueva rama para tus cambios:
   ```bash
   git checkout -b feature/nueva-funcionalidad
   ```
3. Realiza un pull request con una descripci√≥n detallada de tus cambios.

Consulta el archivo `CONTRIBUTING.md` para m√°s detalles sobre c√≥mo contribuir.

---

## **Licencia**
Este proyecto est√° licenciado bajo la licencia MIT. Para m√°s detalles, consulta el archivo `LICENSE`.


